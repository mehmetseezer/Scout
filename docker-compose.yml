version: '3.8'

services:
  backend:
    build:
      context: ./backend
    container_name: backend
    command: >
      sh -c "python manage.py makemigrations --noinput &&
             python manage.py migrate &&
             echo "y" | python manage.py search_index --rebuild &&
             python manage.py runserver 0.0.0.0:8000"
    volumes:
      - ./backend:/app
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
      elasticsearch:
        condition: service_healthy
    environment:
      DJANGO_SETTINGS_MODULE: core.settings
      DATABASE_URL: postgres://postgres:postgres@db:5432/postgres
      CELERY_BROKER_URL: redis://redis:6379/0
    networks:
      - app-network

  frontend:
    build:
      context: ./frontend
    container_name: frontend
    ports:
      - "8080:8080"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: npm run dev -- --host
    networks:
      - app-network

  db:
    image: postgres:latest
    container_name: postgres-db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - app-network

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.1
    container_name: elasticsearch
    environment:
      discovery.type: single-node
      bootstrap.memory_lock: true
      xpack.security.enabled: false
      ES_JAVA_OPTS: "-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"
    volumes:
      - es-data:/usr/share/elasticsearch/data
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 24

  celery:
    build:
      context: ./backend
    container_name: celery-worker
    command: sh -c "celery -A core worker -Q onboarding_queue --loglevel=info --concurrency=2 -n onboarding_worker & 
                    celery -A core worker -Q blog_processing_queue --loglevel=info --concurrency=10 -n blog_worker &
                    celery -A core worker -Q bulk_sync_queue --loglevel=info --concurrency=1 -n bulk_sync_worker &
                    celery -A core worker -Q admin_queue --loglevel=info --concurrency=1 -n admin_worker &
                    celery -A core worker -Q periodic:admin_queue --loglevel=info --concurrency=1 -n periodic:admin_worker &
                    celery -A core worker -Q periodic:bulk_sync_queue --loglevel=info --concurrency=1 -n periodic:bulk_sync_worker"
    depends_on:
      - redis
      - backend
    volumes:
      - ./backend:/app
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
      CELERY_RESULT_BACKEND: redis://redis:6379/0
    networks:
      - app-network

  celery-beat:
    build:
      context: ./backend
    container_name: celery-beat
    command: celery -A core beat --loglevel=info
    depends_on:
      - redis
      - backend
    volumes:
      - ./backend:/app
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
    networks:
      - app-network

  celery-flower:
    image: mher/flower
    container_name: celery-flower
    ports:
      - "5555:5555"
    depends_on:
      - redis
      - backend
    environment:
      CELERY_BROKER_URL: redis://redis:6379/0
    networks:
      - app-network

volumes:
  postgres-data:
  es-data:

networks:
  app-network:
    driver: bridge
